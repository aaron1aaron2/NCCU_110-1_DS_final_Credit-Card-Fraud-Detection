# [Group8] Credit Card Fraud Detection
#### Tags: `Imbalanced data`ã€`Binary classification`ã€`Finance`ã€`Credit Card transaction data`ã€`Time series`

### Groups
|åå­—|ç³»ç´š|å­¸è™Ÿ|
|-|-|-|
|ä½•å½¥å—|è³‡ç§‘ç¢©ä¸€|110753202|
|é™³å‰ç‘„|è³‡ç§‘ç¢©å°ˆä¸€|110971020|
|è‘‰åˆç‘„|çµ±è¨ˆä¸‰|108304046|
|é®‘è•¾é›…|çµ±è¨ˆä¸‰|108304017|
|æ—ä½‘å½¥|çµ±è¨ˆä¸‰|108304015|

## Goal
![](image/ä»»å‹™ç¤ºæ„åœ–.png)

- ğŸ“ **è³‡æ–™** è©²è³‡æ–™é›†åŒ…å«å…©å¤©çš„ä¿¡ç”¨å¡äº¤æ˜“ç´€éŒ„è³‡æ–™ï¼ŒåŒ…å«ä»¥ä¸‹ç‰¹å¾µ28å€‹ PCA ç‰¹å¾µ(V1 ~ V28)ã€äº¤æ˜“é¡(Amount)ã€æ™‚é–“(Time)ï¼Œé æ¸¬ç›®æ¨™ç‚º**æ˜¯å¦ç‚ºè©æ¬ºäº¤æ˜“(Class)**ã€‚
- ğŸ˜¢ **å›°é›£**: å› ç‚ºè©æ¬ºäº¤æ˜“æœ¬ä¾†å°±æ˜¯æ•¸é‡è¼ƒå°‘ï¼Œè³‡æ–™å‘ˆç¾ ***æ¥µåº¦ä¸å¹³è¡¡*** ç‹€æ…‹ã€‚
- ğŸ¯ **ä»»å‹™ç›®æ¨™**: ç”±å‰é¢ ***40 å°æ™‚*** çš„è³‡æ–™(train)é æ¸¬å¾Œé¢  ***8 å°æ™‚*** ç™¼ç”Ÿçš„è©æ¬ºäº¤æ˜“(test)
- ğŸ”— **è³‡æ–™ä¾†æº**: [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)

### Training and testing data set
![](results/0_train_test_split_data.png)


### K-fold methon
![](results/0_kfold_split_threeway.png)

### Baseline model (decision tree)
- maxdepth=10
- miinsplit=20

![](results/6_feature_engineering_baseline_tree.png)

## Demo 
å¯ä»¥åƒè€ƒ `code/2_baseline.R`ï¼Œæœ‰ä½¿ç”¨ R çš„ rpart(æ±ºç­–æ¨¹) ä½œç‚ºé æ¸¬æ¨¡å‹ï¼Œä¸¦åœ¨æˆ‘å€‘å®šç¾© kfold(`output/1_kfold/kfold_idx.rds`) çµ‚æ¸¬è©¦æ¨¡å‹ç©©å®šåº¦ï¼Œå…¶ä¸­åŒ…å« maxdepthã€minsplpit åƒæ•¸æ¸¬è©¦çš„å¯¦é©—æµç¨‹
#### æ±ºç­–æ¨¹çš„åƒæ•¸æ¸¬è©¦(maxdepth)


##### 1. è¨˜éŒ„æ¯çµ„å¯¦é©—åœ¨å„ fold ä¸Šçš„è¡¨ç¾ ->  `output/2_baseline/result.maxdepth.csv`
experiment                |  fold  |  train_accuracy  |  test_accuracy  |  val_accuracy  |  test_precision  |  test_recall  |  test_f1  |  val_precision  |  val_recall  |  val_f1  |  timeuse
--------------------------|--------|------------------|-----------------|----------------|------------------|---------------|-----------|-----------------|--------------|----------|---------
decision trees(depth=1)   |  1     |  0.999           |  0.999          |  0.999         |  0.655           |  0.494        |  0.563    |  0.760          |  0.731       |  0.745   |  7.650
decision trees(depth=1)   |  2     |  0.999           |  0.999          |  0.999         |  0.655           |  0.494        |  0.563    |  0.786          |  0.740       |  0.762   |  3.657
decision trees(depth=1)   |  3     |  0.999           |  0.999          |  0.999         |  0.694           |  0.442        |  0.540    |  0.778          |  0.680       |  0.725   |  3.763
decision trees(depth=1)   |  4     |  0.999           |  0.999          |  0.999         |  0.655           |  0.494        |  0.563    |  0.731          |  0.731       |  0.731   |  3.432
decision trees(depth=5)   |  1     |  1.000           |  1.000          |  0.999         |  0.905           |  0.740        |  0.814    |  0.842          |  0.817       |  0.829   |  12.746
~  |~|~|~|~|~|~|~|~|~|~|
decision trees(depth=15)  |  4     |  1.000           |  0.999          |  0.999         |  0.847           |  0.649        |  0.735    |  0.882          |  0.721       |  0.794   |  28.960
decision trees(depth=20)  |  1     |  1.000           |  1.000          |  0.999         |  0.905           |  0.740        |  0.814    |  0.867          |  0.817       |  0.842   |  31.082
decision trees(depth=20)  |  2     |  1.000           |  0.999          |  0.999         |  0.812           |  0.727        |  0.767    |  0.865          |  0.798       |  0.830   |  29.071
decision trees(depth=20)  |  3     |  0.999           |  0.999          |  0.999         |  0.850           |  0.662        |  0.745    |  0.919          |  0.767       |  0.836   |  30.898
decision trees(depth=20)  |  4     |  1.000           |  0.999          |  0.999         |  0.847           |  0.649        |  0.735    |  0.882          |  0.721       |  0.794   |  30.682
##### 2. æ¯çµ„å¯¦é©—ç”¨ val çš„é¸å‡º fold F1-score è¡¨ç¾æœ€å¥½çš„ model -> `output/2_baseline/result_best.maxdepth.csv`
experiment                |  fold  |  train_accuracy  |  test_accuracy  |  val_accuracy  |  test_precision  |  test_recall  |  test_f1  |  val_precision  |  val_recall  |  val_f1  |  timeuse  |  rank
--------------------------|--------|------------------|-----------------|----------------|------------------|---------------|-----------|-----------------|--------------|----------|-----------|------
decision trees(depth=1)   |  2     |  0.999           |  0.999          |  0.999         |  0.655           |  0.494        |  0.563    |  0.786          |  0.740       |  0.762   |  3.657    |  5
decision trees(depth=5)   |  3     |  0.999           |  0.999          |  0.999         |  0.850           |  0.662        |  0.745    |  0.919          |  0.767       |  0.836   |  12.502   |  4
decision trees(depth=10)  |  1     |  1.000           |  1.000          |  0.999         |  0.905           |  0.740        |  0.814    |  0.867          |  0.817       |  0.842   |  24.222   |  1
decision trees(depth=15)  |  1     |  1.000           |  1.000          |  0.999         |  0.905           |  0.740        |  0.814    |  0.867          |  0.817       |  0.842   |  32.459   |  1
decision trees(depth=20)  |  1     |  1.000           |  1.000          |  0.999         |  0.905           |  0.740        |  0.814    |  0.867          |  0.817       |  0.842   |  31.082   |  1
##### 3. å¯¦é©—çµæœæ¯”è¼ƒ ->  `results/2_baseline.maxdepth.png`
![](results/2_baseline.maxdepth.png)

##### 4. æ‰€æœ‰å¯¦é©—æ¨¡å‹é æ¸¬çµæœéƒ½æœƒè¼¸å‡ºåœ¨ -> `output/2_baseline/pred.maxdepth` 

#### æ¥µç«¯å€¼è™•ç†
##### 1. åˆ©ç”¨ç°¡å–®åˆ†é¡å™¨æ‰¾åƒæ•¸
```
Rscript 3_extremes_filter_searcher.R --method IQR --range -3,3 --target 2:29 --train data/train.csv --test data/test.csv --report output/performance.ef.csv
...
Rscript 3_extremes_filter_searcher.R --method std --range -3,3 --target 3:8,11:20,22:25 --train data/train.csv --test data/test.csv --report output/performance.ef.csv
```
###### åƒæ•¸çµæœ -> `temp/cwayneh/res/performance.ef.csv`
##### 2. æŒ‘é¸åƒæ•¸å¸¶å…¥å¯¦é©—æ¨¡çµ„é€²è¡Œå¯¦é©—
```
Rscript 3_extremes_filter.R
```
##### 3. å¯¦é©—çµæœæ¯”è¼ƒ ->  `results/3_extremes_filter.png`
![](results/3_extremes_filter.png)

##### 4. æ‰€æœ‰å¯¦é©—æ¨¡å‹é æ¸¬çµæœéƒ½æœƒè¼¸å‡ºåœ¨ -> `output/3_extremes_filter/pred.Extremes`

#### è³‡æ–™ä¸å¹³è¡¡è™•ç†
##### 1. åˆ©ç”¨ç°¡å–®åˆ†é¡å™¨æ‰¾åƒæ•¸
```
Rscript 4_imbalance_sampling_searcher.R --nsmp 101 --amp 100 --train data/train.csv --test data/test.csv --report performance.is.csv
...
Rscript 4_imbalance_sampling_searcher.R --nsmp 200 --amp 200 --train data/train.csv --test data/test.csv --report performance.is.csv
```
###### åƒæ•¸çµæœ -> `temp/cwayneh/res/performance.is.csv`
##### 2. æŒ‘é¸åƒæ•¸å¸¶å…¥å¯¦é©—æ¨¡çµ„é€²è¡Œå¯¦é©—
```
Rscript 4_imbalance_sampling.R
```
##### 3. å¯¦é©—çµæœæ¯”è¼ƒ ->  `results/4_imbalance_sampling.png`
![](results/4_imbalance_sampling.png)

##### 4. æ‰€æœ‰å¯¦é©—æ¨¡å‹é æ¸¬çµæœéƒ½æœƒè¼¸å‡ºåœ¨ -> `output/4_imbalance_sampling/pred.Sampling`

## Folder organization and its related information
### docs
* Your presentation, 1101_datascience_FP_<yourID|groupName>.ppt/pptx/pdf, by **Jan. 13**
* åŒ…å«é–‹æœƒç´€éŒ„ã€å·¥ä½œé€²åº¦

### data 
- `train.csv`
  - å–å‰ 40 å°æ™‚çš„è³‡æ–™ (Time æ¬„ä½ < 144000)
  - å…± 224865 ç­†è³‡æ–™
  - ç›®æ¨™æ¬„ä½ Class æ¯”ä¾‹: 0.001846 
- `test.csv` :
  - å–å¾Œ 8 å°æ™‚çš„è³‡æ–™ (Time æ¬„ä½ >= 144000)
  - å…± 59942 ç­†è³‡æ–™
  - ç›®æ¨™æ¬„ä½ Class æ¯”ä¾‹: 0.001285 

### code

* Which method do you use?
* What is a null model for comparison?
* How do your perform evaluation? ie. cross-validation, or addtional indepedent data set

### results
- ğŸ‘‘ é–€æª»å€¼çš„è¨­å®š

![](results/final_result.png)

## References
- _Tommy Huang, æ©Ÿå™¨å­¸ç¿’: Ensemble learningä¹‹Baggingã€Boostingå’ŒAdaBoost, 2018, medium. ([source](https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-ensemble-learning%E4%B9%8Bbagging-boosting%E5%92%8Cadaboost-af031229ebc3))_
- _Tatiana Sennikova, How to Build a Baseline Model,  2020, medium. ([source](https://towardsdatascience.com/how-to-build-a-baseline-model-be6ce42389fc))_
- _Google, Classification on imbalanced data, 2021,  Tensorflow tutorials. ([source](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data))_
- _Google, Validation Set: Another Partition, 2020, google developers(Machine Learning Crash Course). ([source](https://developers.google.com/machine-learning/crash-course/validation/another-partition))_
- _rpart.control: Control for Rpart Fits, RDocumentation.  ([source](https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart.control))_
- _rpart-decision-trees-in-r, learnbymarketing. ([source](https://www.learnbymarketing.com/tutorials/rpart-decision-trees-in-r/))_
- _Ben, rpart complexity parameter confusion, 2015, stackexchange(Cross Validated).([source](https://stats.stackexchange.com/questions/117908/rpart-complexity-parameter-confusion))_

## environment
- R version 3.6.3
- rpart: 4.1-15
- ggplot2: 3.3.5
- tidyr: 1.1.3
- dplyr: 1.0.6  

### sessionInfo
#### `./docs/sessionInfo(yen-nan ho).txt`
```
R version 3.6.3 (2020-02-29)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19043)

Matrix products: default

locale:
[1] LC_COLLATE=Chinese (Traditional)_Taiwan.950 
[2] LC_CTYPE=Chinese (Traditional)_Taiwan.950   
[3] LC_MONETARY=Chinese (Traditional)_Taiwan.950
[4] LC_NUMERIC=C                                
[5] LC_TIME=Chinese (Traditional)_Taiwan.950    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
[1] tidyr_1.1.3      lattice_0.20-38  rpart_4.1-15    
[4] ica_1.0-2        corrplot_0.92    factoextra_1.0.7
[7] ggplot2_3.3.5    ranger_0.12.1   

loaded via a namespace (and not attached):
 [1] tidyselect_1.1.1 purrr_0.3.4      carData_3.0-4   
 [4] colorspace_2.0-1 vctrs_0.3.8      generics_0.1.1  
 [7] utf8_1.2.1       rlang_0.4.11     ggpubr_0.4.0    
[10] pillar_1.6.2     glue_1.4.2       withr_2.4.2     
[13] DBI_1.1.1        foreach_1.5.1    lifecycle_1.0.0 
[16] plyr_1.8.6       munsell_0.5.0    ggsignif_0.6.3  
[19] gtable_0.3.0     codetools_0.2-16 labeling_0.4.2  
[22] fansi_0.4.2      broom_0.7.10     Rcpp_1.0.6      
[25] readr_1.4.0      backports_1.2.1  scales_1.1.1    
[28] abind_1.4-5      farver_2.1.0     hms_1.1.1       
[31] digest_0.6.27    rstatix_0.7.0    dplyr_1.0.6     
[34] ggrepel_0.9.1    grid_3.6.3       cli_2.5.0       
[37] tools_3.6.3      magrittr_2.0.1   tibble_3.1.1    
[40] crayon_1.4.1     car_3.0-12       pkgconfig_2.0.3 
[43] ellipsis_0.3.2   MASS_7.3-51.5    Matrix_1.2-18   
[46] assertthat_0.2.1 rstudioapi_0.13  iterators_1.0.13
[49] R6_2.5.1         nlme_3.1-144     compiler_3.6.3  

```
